{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from typing import Tuple, List\n",
    "from scipy.stats import ttest_1samp\n",
    "import re\n",
    "import pickle\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from typing import List, Set, Dict, Tuple, NewType, Optional\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_kwargs(data:pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    construct_query = []\n",
    "    for key, item in kwargs.items():\n",
    "        construct_query.append(key + \" == \" + str(item))\n",
    "    construct_query = ' & '.join(construct_query)\n",
    "    return data.query(construct_query)\n",
    "\n",
    "def get_number_of_unique_rows(data:pd.DataFrame, col_name:str) -> int:\n",
    "    return len(set(data[col_name]))\n",
    "\n",
    "def get_row_number(system_nr:int, query_nr:int, nr_queries:int) -> int:\n",
    "    ii = system_nr - 1\n",
    "    jj = query_nr - 1\n",
    "    return ii * nr_queries + jj\n",
    "\n",
    "def create_result_df(nr_systems:int, nr_queries:int) -> pd.DataFrame:\n",
    "    col_names = ['system_number', 'query_number', 'P@10', 'R@50', 'r-precision', 'AP', 'nDCG@10', 'nDCG@20']\n",
    "    result_df = pd.DataFrame(np.zeros((nr_systems * nr_queries, len(col_names))), columns=col_names)\n",
    "    result_df['system_number'] = pd.to_numeric(result_df['system_number'], downcast='integer')\n",
    "    result_df['query_number'] = pd.to_numeric(result_df['query_number'], downcast='integer')\n",
    "    \n",
    "    for ii in range(nr_systems):\n",
    "        for jj in range(nr_queries):\n",
    "            row_nr = get_row_number(ii+1, jj+1, nr_queries)\n",
    "            result_df.at[row_nr, 'system_number'] = ii+1\n",
    "            result_df.at[row_nr, 'query_number'] = jj+1\n",
    "    return result_df\n",
    "\n",
    "def calculate_precision_at_10(sys_results:pd.DataFrame, qrels:pd.DataFrame, system_number:int, \n",
    "                             query_number:int) -> float:\n",
    "    retrieved_docs = list(filter_on_kwargs(sys_results, system_number=system_number, \n",
    "                                           query_number=query_number)['doc_number'])\n",
    "    relevant_docs = set(filter_on_kwargs(qrels, query_id=query_number)['doc_id'])\n",
    "    \n",
    "    TP = 0\n",
    "    for doc in retrieved_docs[:10]:\n",
    "        if doc in relevant_docs:\n",
    "            TP += 1\n",
    "    return TP/10\n",
    "\n",
    "def calculate_all_precision_at_10(sys_results:pd.DataFrame, qrels:pd.DataFrame, nr_systems:int, \n",
    "                                 nr_queries:int, result_df:pd.DataFrame):\n",
    "    for ii in range(1, nr_systems+1):\n",
    "        for jj in range(1, nr_queries+1):\n",
    "            precision = calculate_precision_at_10(sys_results, qrels, ii, jj)\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'P@10'] = precision\n",
    "\n",
    "def calculate_recall_at_50(sys_results:pd.DataFrame, qrels:pd.DataFrame, system_number:int, \n",
    "                             query_number:int) -> float:\n",
    "    retrieved_docs = list(filter_on_kwargs(sys_results, system_number=system_number, \n",
    "                                           query_number=query_number)['doc_number'])\n",
    "    relevant_docs = set(filter_on_kwargs(qrels, query_id=query_number)['doc_id'])\n",
    "    \n",
    "    TP = 0\n",
    "    for doc in retrieved_docs[:50]:\n",
    "        if doc in relevant_docs:\n",
    "            TP += 1\n",
    "\n",
    "    FN = len(relevant_docs.difference(set(retrieved_docs[:50])))\n",
    "    return TP/(TP + FN)\n",
    "\n",
    "def calculate_all_recall_at_50(sys_results:pd.DataFrame, qrels:pd.DataFrame, nr_systems:int, \n",
    "                                 nr_queries:int, result_df:pd.DataFrame):\n",
    "    for ii in range(1, nr_systems+1):\n",
    "        for jj in range(1, nr_queries+1):\n",
    "            recall = calculate_recall_at_50(sys_results, qrels, ii, jj)\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'R@50'] = recall\n",
    "\n",
    "def calculate_R_precision(sys_results:pd.DataFrame, qrels:pd.DataFrame, system_number:int, \n",
    "                          query_number:int) -> float:\n",
    "    retrieved_docs = list(filter_on_kwargs(sys_results, system_number=system_number, \n",
    "                                           query_number=query_number)['doc_number'])\n",
    "    relevant_docs = set(filter_on_kwargs(qrels, query_id=query_number)['doc_id'])\n",
    "    R = len(relevant_docs)\n",
    "    \n",
    "    TP = 0\n",
    "    for doc in retrieved_docs[:R]:\n",
    "        if doc in relevant_docs:\n",
    "            TP += 1\n",
    "    return TP/R\n",
    "\n",
    "def calculate_all_R_precision(sys_results:pd.DataFrame, qrels:pd.DataFrame, nr_systems:int, \n",
    "                              nr_queries:int, result_df:pd.DataFrame):\n",
    "    for ii in range(1, nr_systems+1):\n",
    "        for jj in range(1, nr_queries+1):\n",
    "            R_precision = calculate_R_precision(sys_results, qrels, ii, jj)\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'r-precision'] = R_precision\n",
    "\n",
    "def calculate_AP(sys_results:pd.DataFrame, qrels:pd.DataFrame, system_number:int, \n",
    "                 query_number:int) -> float:\n",
    "    retrieved_docs = list(filter_on_kwargs(sys_results, system_number=system_number, \n",
    "                                           query_number=query_number)['doc_number'])\n",
    "    relevant_docs = set(filter_on_kwargs(qrels, query_id=query_number)['doc_id'])\n",
    "    \n",
    "    R = len(relevant_docs)\n",
    "    \n",
    "    AP = 0\n",
    "    TP = 0\n",
    "    for ii, doc in enumerate(retrieved_docs):\n",
    "        if doc in relevant_docs:\n",
    "            TP += 1\n",
    "            AP += TP/(ii+1)\n",
    "    AP = AP/R\n",
    "    return AP\n",
    "\n",
    "def calculate_all_AP(sys_results:pd.DataFrame, qrels:pd.DataFrame, nr_systems:int, \n",
    "                              nr_queries:int, result_df:pd.DataFrame):\n",
    "    for ii in range(1, nr_systems+1):\n",
    "        for jj in range(1, nr_queries+1):\n",
    "            AP = calculate_AP(sys_results, qrels, ii, jj)\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'AP'] = AP\n",
    "\n",
    "def calculate_nDCG(sys_results:pd.DataFrame, qrels:pd.DataFrame, system_number:int, \n",
    "                   query_number:int) -> float:\n",
    "    retrieved_docs = list(filter_on_kwargs(sys_results, system_number=system_number, \n",
    "                                           query_number=query_number)['doc_number'])\n",
    "    qrels_subset = filter_on_kwargs(qrels, query_id=query_number)\n",
    "    \n",
    "    relevant_doc_ids = list(qrels_subset['doc_id'])\n",
    "    relevant_doc_relevance = list(qrels_subset['relevance'])\n",
    "    relevant_dict = dict()\n",
    "    for ii, doc_id in enumerate(relevant_doc_ids):\n",
    "        relevant_dict[doc_id] = relevant_doc_relevance[ii]\n",
    "    \n",
    "    nDCG_10 = 0\n",
    "    nDCG_20 = 0\n",
    "    DCG_10 = 0\n",
    "    DCG_20 = 0\n",
    "    iDCG_k = 0\n",
    "    sorted_doc_relevance = sorted(relevant_doc_relevance, reverse=True)\n",
    "    for ii, doc in enumerate(retrieved_docs[:20]):\n",
    "        if doc in relevant_dict:\n",
    "            if ii == 0:\n",
    "                DCG_10 += relevant_dict[doc]\n",
    "                DCG_20 += relevant_dict[doc]\n",
    "            elif ii < 10:\n",
    "                DCG_10 += relevant_dict[doc] / np.log2(ii+1)\n",
    "                DCG_20 += relevant_dict[doc] / np.log2(ii+1)\n",
    "            else:\n",
    "                DCG_20 += relevant_dict[doc] / np.log2(ii+1)\n",
    "            \n",
    "        if ii == 0:\n",
    "            iDCG_k += sorted_doc_relevance[ii]\n",
    "        elif ii < len(sorted_doc_relevance):\n",
    "            iDCG_k += sorted_doc_relevance[ii] / np.log2(ii+1)\n",
    "            \n",
    "        if ii == 9:\n",
    "            nDCG_10 = DCG_10 / iDCG_k\n",
    "            \n",
    "        if ii == 19:\n",
    "            nDCG_20 = DCG_20 / iDCG_k\n",
    "    return nDCG_10, nDCG_20\n",
    "\n",
    "def calculate_all_nDCG(sys_results:pd.DataFrame, qrels:pd.DataFrame, nr_systems:int, \n",
    "                       nr_queries:int, result_df:pd.DataFrame):\n",
    "    for ii in range(1, nr_systems+1):\n",
    "        for jj in range(1, nr_queries+1):\n",
    "            nDCG_10, nDCG_20 = calculate_nDCG(sys_results, qrels, ii, jj)\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'nDCG@10'] = nDCG_10\n",
    "            result_df.at[get_row_number(ii, jj, nr_queries), 'nDCG@20'] = nDCG_20\n",
    "\n",
    "def print_result_df(result_df:pd.DataFrame, nr_systems:int, nr_queries:int, file_name:str='ir_eval.csv'):\n",
    "    score_means = np.zeros((nr_systems, 6))\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(','.join(result_df.columns)+'\\n')\n",
    "        for ii in range(nr_systems):\n",
    "            for jj in range(nr_queries):\n",
    "                row_nr = get_row_number(ii+1, jj+1, nr_queries)\n",
    "                row = result_df.loc[row_nr, :]\n",
    "                line = str(int(row[0])) + ',' + str(int(row[1])) + ','\n",
    "                \n",
    "                rest_of_line = ','.join(map(str, [round(x, 3) for x in row[2:]]))\n",
    "                line += rest_of_line + '\\n'\n",
    "                f.write(line)\n",
    "            line = str(ii+1) + \",\" + \"mean\" + \",\"\n",
    "            row_nr = get_row_number(ii+1, 1, nr_queries)\n",
    "            relevant_stats = np.array(result_df.iloc[row_nr:row_nr+nr_queries, 2:])\n",
    "            \n",
    "            means = np.mean(relevant_stats, axis=0)\n",
    "            score_means[ii, :] = means\n",
    "            \n",
    "            rest_of_line = ','.join(map(str, [round(x, 3) for x in means]))\n",
    "            line += rest_of_line + '\\n'\n",
    "            f.write(line)\n",
    "    return score_means\n",
    "\n",
    "def p_values(result_df:pd.DataFrame, score_means:np.ndarray, nr_queries:int, col_names:List[str]):\n",
    "    nr_systems = score_means.shape[0]\n",
    "    for ii, stat in enumerate(col_names):\n",
    "        # For the current stat, need to select the top 2 means.\n",
    "        means = score_means[:, ii]\n",
    "        \n",
    "        sorted_idx = np.argsort(means)\n",
    "        first_idx = sorted_idx[-1]\n",
    "        second_idx = sorted_idx[-2]\n",
    "        last = -2\n",
    "        \n",
    "        first_scores = np.array(result_df[stat][nr_queries*first_idx : nr_queries*first_idx + nr_queries])\n",
    "        second_scores = np.array(result_df[stat][nr_queries*second_idx : nr_queries*second_idx + nr_queries])\n",
    "        diff = first_scores - second_scores\n",
    "        \n",
    "        while np.std(diff) == 0 and last >= -nr_systems:\n",
    "            last -= 1\n",
    "            print(\"System : \" + str(second_idx+1) + \" has identical performance with the first system.\")\n",
    "            second_idx = sorted_idx[last]\n",
    "            second_scores = np.array(result_df[stat][nr_queries*second_idx : nr_queries*second_idx + nr_queries])\n",
    "            diff = first_scores - second_scores\n",
    "        \n",
    "        t_value, p_value = ttest_1samp(diff, 0)\n",
    "        \n",
    "        print('For statistic ' + stat + ': best = ' + str(first_idx+1) + '; 2nd best = ' + \n",
    "             str(second_idx+1) + '; P-value: ' + str(p_value) + '; T-value: ' + str(t_value))\n",
    "        \n",
    "class SimpleTokenizer():\n",
    "    def __init__(self, pattern:str):\n",
    "        \"\"\"Initialise the regular expression which will be used to tokenize our expression.\n",
    "\n",
    "        Args:\n",
    "            pattern (str): pattern to be used.\n",
    "        \"\"\"\n",
    "        self.regexp = re.compile(pattern, re.MULTILINE | re.DOTALL)\n",
    "    \n",
    "    def tokenize_text_lines(self, text_lines:List[str]) -> List[str]:\n",
    "        \"\"\"Accepts a list of strings. Tokenizes each string and creates a list of the tokens.\n",
    "\n",
    "        Args:\n",
    "            text_lines (List[str]): List of strings.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of tokens produced from the input strings.\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        for line in text_lines:\n",
    "            tokens += self.regexp.findall(line)\n",
    "        return tokens\n",
    "    \n",
    "    def tokenize_list_of_strings(self, string_list:List[str]) -> List[List[str]]:\n",
    "        list_of_tokens = []\n",
    "        for string in string_list:\n",
    "            list_of_tokens.append(self.regexp.findall(string))\n",
    "        return list_of_tokens\n",
    "\n",
    "def construct_stopwords_set(stopwords_file_name:str) -> Set[str]:\n",
    "    \"\"\"Reads stopwords from stopwords_file_name and saves them in a set.\n",
    "\n",
    "    Args:\n",
    "        stopwords_file_name (str): Stop words file.\n",
    "\n",
    "    Returns:\n",
    "        Set[str]: [description]\n",
    "    \"\"\"\n",
    "    with open(stopwords_file_name, 'r') as f:\n",
    "        read_stopwords = f.read().splitlines()\n",
    "    stopwords_set = set(read_stopwords)\n",
    "    stopwords_set.update(stopwords.words(\"english\"))\n",
    "    return stopwords_set\n",
    "\n",
    "class SimplePreprocessor():\n",
    "    \"\"\"Class for pre-processing text. Given a list of strings, it tokenizes them, removes stop words, lowercases and stems them.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer:SimpleTokenizer, stop_words_set:Set[str], stemmer:PorterStemmer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stop_words_set = stop_words_set\n",
    "        self.stemmer = stemmer\n",
    "    \n",
    "    @staticmethod\n",
    "    def lowercase_word(word:str) -> str:\n",
    "        return str.lower(word)\n",
    "    \n",
    "    def remove_stop_words_lowercase_and_stem(self, tokens:List[str]) -> List[str]:\n",
    "        final_tokens = []\n",
    "        for token in tokens:\n",
    "            lowercase_token = SimplePreprocessor.lowercase_word(token)\n",
    "            if lowercase_token not in self.stop_words_set:\n",
    "                stemmed_token = self.stemmer.stem(lowercase_token)\n",
    "                final_tokens.append(stemmed_token)\n",
    "        return final_tokens\n",
    "    \n",
    "    def process_text_lines(self, text_lines:List[str]) -> List[str]:\n",
    "        tokens = self.tokenizer.tokenize_text_lines(text_lines)\n",
    "        tokens = self.remove_stop_words_lowercase_and_stem(tokens)\n",
    "        return tokens\n",
    "\n",
    "def pickle_object(obj:object, file_name:str):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def unpickle_object(file_name:str) -> object:\n",
    "    with open(file_name, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "# Read the tsv file + extract the 3 corpora.\n",
    "# Assumption: 3 corpora Quran, OT, NT.\n",
    "def read_tsv_extract_corpora(tsv_file_name:str, corpus_names_to_int:Dict[str, int]) -> Dict[int, List[str]]:\n",
    "    corpora = dict()\n",
    "    for value in corpus_names_to_int.values():\n",
    "        corpora[value] = []\n",
    "    with open(tsv_file_name, mode='r', newline='\\n') as f:\n",
    "        read_tsv = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in read_tsv:\n",
    "            corpus_name = row[0]\n",
    "            corpus_id = corpus_names_to_int[corpus_name]\n",
    "            corpora[corpus_id].append(row[1])\n",
    "    return corpora\n",
    "\n",
    "def preprocess_corpora(corpora:Dict[int, List[str]], preprocessor:SimplePreprocessor) -> Dict[int, List[List[str]]]:\n",
    "    preprocessed_corpora = dict()\n",
    "    for key in corpora.keys():\n",
    "        preprocessed_corpora[key] = []\n",
    "        for document in corpora[key]:\n",
    "            document_terms = preprocessor.process_text_lines([document])\n",
    "            preprocessed_corpora[key].append(document_terms)\n",
    "    return preprocessed_corpora\n",
    "\n",
    "# ----------------------------------CREATE INDEX AND DOCID SET----------------------------------\n",
    "Index = NewType('Index', Dict[str, Dict[int, Dict[int, int]]])\n",
    "def read_corpora_and_create_index(corpora:Dict[int, List[List[str]]]) -> Tuple[Index, Dict[int, int]]:\n",
    "    \"\"\"Reads input trec file and creates a positional inverted index from it, and it also creates a set containing all document IDs.\n",
    "\n",
    "    Args:\n",
    "        input_file_name (str): input trec file name.\n",
    "        preprocessor (SimplePreprocessor): initialized SimplePreprocessor.\n",
    "    \"\"\"\n",
    "    index = dict()\n",
    "    corpora_nr_docs = dict()\n",
    "    \n",
    "    for corpus_id in corpora.keys():\n",
    "        corpora_nr_docs[corpus_id] = 0\n",
    "        for (doc_id, doc_tokens) in enumerate(corpora[corpus_id]):\n",
    "            corpora_nr_docs[corpus_id] += 1\n",
    "            for token in doc_tokens:\n",
    "                if token in index:\n",
    "                    if corpus_id in index[token]:\n",
    "                        if doc_id in index[token][corpus_id]:\n",
    "                            index[token][corpus_id][doc_id] += 1\n",
    "                        else:\n",
    "                            index[token][corpus_id][doc_id] = 1\n",
    "                    else:\n",
    "                        index[token][corpus_id] = dict()\n",
    "                        index[token][corpus_id][doc_id] = 1\n",
    "                else:\n",
    "                    index[token] = dict()\n",
    "                    index[token][corpus_id] = dict()\n",
    "                    index[token][corpus_id][doc_id] = 1\n",
    "                    \n",
    "                    \n",
    "        print(\"Index construction for corpus \" + str(corpus_id+1) + \" finished.\")\n",
    "\n",
    "    return index, corpora_nr_docs\n",
    "\n",
    "def calculate_freq_term(index:Index, term:str) -> int:\n",
    "    if term not in index:\n",
    "        return 0\n",
    "    \n",
    "    frequency = 0\n",
    "    for corpus_id in index[term]:\n",
    "        for doc_id in index[term][corpus_id]:\n",
    "            frequency += index[term][corpus_id][doc_id]\n",
    "    return frequency\n",
    "\n",
    "\n",
    "def remove_low_freq_words_from_index(corpora_index:Index, threshold_freq:int) -> Index:\n",
    "    new_index = dict()\n",
    "\n",
    "    for term in corpora_index:\n",
    "        freq = calculate_freq_term(corpora_index, term)\n",
    "        if freq >= threshold_freq:\n",
    "            new_index[term] = corpora_index[term]\n",
    "    return new_index\n",
    "    \n",
    "\n",
    "def compute_MI_score_term_corpus(N:int, N_00:int, N_01:int, N_10:int, N_11:int) -> float:\n",
    "    N_1x = N_10 + N_11 # 0 iff no corpus contains the term (impossible)\n",
    "    N_x1 = N_01 + N_11 # 0 iff the corpus doesn't contain any documents (may be possible with a cheater corpus)\n",
    "    N_0x = N_01 + N_00 # 0 iff ALL documents contain term t (may be possible if you miss a stop word or you tokenize incorrectly -- need to check for assignment imo)\n",
    "    N_x0 = N_10 + N_00 # 0 N_10 = 0 iff no other documents (from other corpora) contain the term. N_00 = 0 iff every document (from other corpora) contain the term.\n",
    "    # N_x0 can be 0 iff we have a single corpus.\n",
    "    \n",
    "    # 0 * log(0) = 0 by convention.\n",
    "    MI_score = 0\n",
    "    if N_10 != 0:\n",
    "        MI_score += (N_10/N) * np.log2((N * N_10)/(N_1x * N_x0))\n",
    "    \n",
    "    if N_01 != 0:\n",
    "        MI_score += (N_01/N) * np.log2((N * N_01)/(N_0x * N_x1))\n",
    "    \n",
    "    if N_11 != 0:\n",
    "        MI_score += (N_11/N) * np.log2((N * N_11)/(N_1x * N_x1))\n",
    "    \n",
    "    if N_00 != 0:\n",
    "        MI_score += (N_00/N) * np.log2((N * N_00)/(N_0x * N_x0))\n",
    "        \n",
    "    return MI_score\n",
    "\n",
    "def compute_chi_score_term_corpus(N:int, N_00:int, N_01:int, N_10:int, N_11:int) -> float:\n",
    "    chi_score_numerator = (N_11 + N_10 + N_01 + N_00) * (N_11 * N_00 - N_10 * N_01) ** 2\n",
    "    # Same warning as above. Term in all documents, in no document, or one-corpus dataset.\n",
    "    chi_score_denominator = (N_11 + N_01) * (N_11 + N_10) * (N_10 + N_00) * (N_01 + N_00)\n",
    "    chi_score = chi_score_numerator/chi_score_denominator\n",
    "    \n",
    "    return chi_score\n",
    "\n",
    "def compute_MI_chi_scores(index:Index, corpora_nr_docs:Dict[int, int], corpora_ids:List[int]) -> Tuple[Dict[int, List[Tuple[str, int]]], Dict[int, List[Tuple[str, int]]]]:\n",
    "    MI_scores = dict()\n",
    "    chi_scores = dict()\n",
    "\n",
    "    for corpus_id in corpora_ids:\n",
    "        MI_scores[corpus_id] = []\n",
    "        chi_scores[corpus_id] = []\n",
    "    \n",
    "    N = 0\n",
    "    for corpus_id in corpora_nr_docs:\n",
    "        N += corpora_nr_docs[corpus_id]\n",
    "    \n",
    "    nr_docs_which_contain_term = dict()\n",
    "    for term in index:\n",
    "        N_1x = 0\n",
    "        for corpus_id in index[term]:\n",
    "            N_1x += len(index[term][corpus_id])\n",
    "        nr_docs_which_contain_term[term] = N_1x\n",
    "    \n",
    "    for term in index:\n",
    "        for corpus_id in corpora_ids:\n",
    "            N_11 = 0\n",
    "            if corpus_id not in index[term]:\n",
    "                N_01 = corpora_nr_docs[corpus_id]\n",
    "            else:\n",
    "                for _ in index[term][corpus_id]:\n",
    "                    N_11 += 1\n",
    "                N_01 = corpora_nr_docs[corpus_id] - N_11\n",
    "            N_10 = nr_docs_which_contain_term[term] - N_11\n",
    "            N_00 = N - nr_docs_which_contain_term[term] - N_01\n",
    "\n",
    "            MI_scores[corpus_id].append((term, compute_MI_score_term_corpus(N, N_00, N_01, N_10, N_11)))\n",
    "            chi_scores[corpus_id].append((term, compute_chi_score_term_corpus(N, N_00, N_01, N_10, N_11)))\n",
    "    \n",
    "    for corpus_id in MI_scores:\n",
    "        MI_scores[corpus_id] = sorted(MI_scores[corpus_id], key=itemgetter(1), reverse=True)\n",
    "        chi_scores[corpus_id] = sorted(chi_scores[corpus_id], key=itemgetter(1), reverse=True)\n",
    "    return MI_scores, chi_scores\n",
    "\n",
    "def print_top_k_terms_for_each_corpus(MI_scores, chi_scores, int_to_corpus_names, k):\n",
    "    for corpus_id in MI_scores.keys():\n",
    "        corpus_name = int_to_corpus_names[corpus_id]\n",
    "        # print('Top ' + str(k) + ' terms in ' + corpus_name + ' by MI score: ')\n",
    "        # print(MI_scores[corpus_id][:k])\n",
    "        # print('Top ' + str(k) + ' terms in ' + corpus_name + ' by Chi-squared score: ')\n",
    "        # print(chi_scores[corpus_id][:k])\n",
    "        \n",
    "        file_name = corpus_name + '_' + 'MI.csv'\n",
    "        file_content = \"term,mi\\n\"\n",
    "        for (term, MI_score) in MI_scores[corpus_id][:k]:\n",
    "            file_content += term + ',' + str(round(MI_score, 5)) + '\\n'\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write(file_content)\n",
    "        \n",
    "        file_name = corpus_name + '_' + 'chi.csv'\n",
    "        file_content = \"term,chisq\\n\"\n",
    "        for (term, chi_score) in chi_scores[corpus_id][:k]:\n",
    "            file_content += term + ',' + str(round(chi_score, 3)) + '\\n'\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write(file_content)\n",
    "            \n",
    "def write_topic_words_to_file(topic_words:List[Tuple[str, float]], corpus_id:int):\n",
    "    file_name = \"topic_words_corpus_\" + str(corpus_id) + \".csv\"\n",
    "    content = \"Term,Score\\n\"\n",
    "    for term, score in topic_words:\n",
    "        content += term + \",\" + str(round(score, 3)) + '\\n'\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def run_topics_task(corpora:Dict[int, List[List[str]]], corpora_nr_docs:Dict[int, int], num_topics=20):\n",
    "    clean_docs = []\n",
    "    for corpus_id in corpora:\n",
    "        clean_docs += corpora[corpus_id]\n",
    "    \n",
    "    dictionary = Dictionary(clean_docs)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.6)\n",
    "    corpus = [dictionary.doc2bow(text) for text in clean_docs]\n",
    "    lda = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=25)\n",
    "    \n",
    "    corpora_topics_scores = dict()\n",
    "    for corpus_id in corpora:\n",
    "        corpora_topics_scores[corpus_id] = dict()\n",
    "        for ii in range(num_topics):\n",
    "            corpora_topics_scores[corpus_id][ii] = 0\n",
    "    \n",
    "    # Sum topic probs for each corpus.\n",
    "    for corpus_id in corpora:\n",
    "        for doc in corpora[corpus_id]:\n",
    "            doc_topics = lda.get_document_topics(dictionary.doc2bow(doc), 0)\n",
    "            for (topic_id, topic_prob) in doc_topics:\n",
    "                corpora_topics_scores[corpus_id][topic_id] += topic_prob\n",
    "    \n",
    "    # Normalise topic probs.\n",
    "    for corpus_id in corpora:\n",
    "        corpus_nr_docs = corpora_nr_docs[corpus_id]\n",
    "        for topic_id in range(num_topics):\n",
    "            corpora_topics_scores[corpus_id][topic_id] /= corpus_nr_docs\n",
    "    \n",
    "    # Select top topic for each corpus.\n",
    "    corpora_top_topic = dict()\n",
    "    for corpus_id in corpora:\n",
    "        top_topic = -1\n",
    "        top_score = 0\n",
    "        for topic_id in range(num_topics):\n",
    "            topic_score = corpora_topics_scores[corpus_id][topic_id]\n",
    "            if topic_score > top_score:\n",
    "                top_topic = topic_id\n",
    "                top_score = topic_score\n",
    "        corpora_top_topic[corpus_id] = top_topic\n",
    "    \n",
    "    for corpus_id in corpora:\n",
    "        top_topic = corpora_top_topic[corpus_id]\n",
    "        print('Top topic for corpus: ' + str(corpus_id) + \" is topic nr \" + str(top_topic))\n",
    "        print(lda.print_topic(top_topic, 10))\n",
    "        topic_words = lda.show_topic(top_topic, 10)\n",
    "        write_topic_words_to_file(topic_words, corpus_id)\n",
    "    \n",
    "    print('\\n')\n",
    "    for ii in range(num_topics):\n",
    "        print('Topic ' + str(ii) + ': ' + str(round(corpora_topics_scores[0][ii], 3)) + ' ' + \n",
    "              str(round(corpora_topics_scores[1][ii], 3)) + ' ' + \n",
    "              str(round(corpora_topics_scores[2][ii], 3)))\n",
    "    \n",
    "    print('\\n')\n",
    "    for ii in range(num_topics):\n",
    "        print('Topic ' + str(ii) + ' words: ')\n",
    "        print(lda.print_topic(ii, 10))\n",
    "    \n",
    "    return lda\n",
    "\n",
    "class NoStemmer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def stem(self, token:str) -> str:\n",
    "        return token\n",
    "\n",
    "class BOW():\n",
    "    def __init__(self):\n",
    "        self.token_to_id = dict()\n",
    "        self.id_to_token = dict()\n",
    "    \n",
    "    @property\n",
    "    def nr_tokens(self) -> int:\n",
    "        return len(self.token_to_id)\n",
    "    \n",
    "    @property\n",
    "    def oov_token(self) -> int:\n",
    "        return len(self.token_to_id)\n",
    "    \n",
    "    def transform_tokenized_sent(self, tokenized_sent:List[str]) -> List[int]:\n",
    "        output = []\n",
    "        for token in tokenized_sent:\n",
    "            if token not in self.token_to_id:\n",
    "                # print('OOV Token detected') # debug stmt\n",
    "                output.append(self.oov_token)\n",
    "            else:\n",
    "                output.append(self.token_to_id[token])\n",
    "        return output\n",
    "    \n",
    "    def add_transform_tokenized_sents(self, tokenized_sents:List[List[str]]) -> List[List[int]]:\n",
    "        output = []\n",
    "        for sent in tokenized_sents:\n",
    "            self.add_list_of_tokens(sent)\n",
    "            output.append(self.transform_tokenized_sent(sent))\n",
    "        return output\n",
    "    \n",
    "    def transform_tokenized_sents(self, tokenized_sents:List[List[str]]) -> List[List[int]]:\n",
    "        output = []\n",
    "        for sent in tokenized_sents:\n",
    "            output.append(self.transform_tokenized_sent(sent))\n",
    "        return output\n",
    "    \n",
    "    def reverse_transform_sent(self, id_sent:List[int]) -> List[str]:\n",
    "        output = []\n",
    "        for token_id in id_sent:\n",
    "            if token_id not in self.id_to_token:\n",
    "                output.append(\"OOV_term\")\n",
    "            else:\n",
    "                output.append(self.id_to_token[token_id])\n",
    "        return output\n",
    "    \n",
    "    def reverse_transform_sents(self, id_sents:List[List[int]]) -> List[List[str]]:\n",
    "        output = []\n",
    "        for sent in id_sents:\n",
    "            output.append(self.reverse_transform_sent(sent))\n",
    "        return output\n",
    "        \n",
    "    def add_token(self, token:str):\n",
    "        if token not in self.token_to_id:\n",
    "            nr_tokens = len(self.token_to_id)\n",
    "            self.token_to_id[token] = nr_tokens\n",
    "            self.id_to_token[nr_tokens] = token\n",
    "    \n",
    "    def add_list_of_tokens(self, tokens:List[str]):\n",
    "        for token in tokens:\n",
    "            self.add_token(token)\n",
    "            \n",
    "    def get_token_id(self, token:str) -> int:\n",
    "        if token not in self.token_to_id:\n",
    "            print(\"Token \" + token + \" not in the BOW\")\n",
    "            return -1\n",
    "        else:\n",
    "            return self.token_to_id[token]\n",
    "    \n",
    "    def get_token_from_id(self, token_id:int) -> str:\n",
    "        if token_id not in self.id_to_token:\n",
    "            print(\"Token id \" + str(token_id) + \" is not in the BOW.\")\n",
    "            return \"\"\n",
    "        else:\n",
    "            return self.id_to_token[token]\n",
    "\n",
    "def tokenize_corpora(corpora:Dict[int, List[str]], \n",
    "                     tokenizer:SimpleTokenizer) -> Dict[int, List[List[str]]]:\n",
    "    tokenized_corpora = dict()\n",
    "    for key in corpora.keys():\n",
    "        tokenized_corpora[key] = []\n",
    "        for document in corpora[key]:\n",
    "            document_terms = tokenizer.tokenize_text_lines([document])\n",
    "            tokenized_corpora[key].append(document_terms)\n",
    "    return tokenized_corpora\n",
    "\n",
    "def docs_to_bow_sents(docs:List[List[str]], ref_bow:Optional[BOW]=None) -> Tuple[List[List[int]], BOW]:\n",
    "    if ref_bow is None:\n",
    "        bow = BOW()\n",
    "        bow_sents = bow.add_transform_tokenized_sents(docs)\n",
    "        return bow_sents, bow \n",
    "    else:\n",
    "        bow_sents = ref_bow.transform_tokenized_sents(docs)\n",
    "        return bow_sents, _\n",
    "\n",
    "def bow_sents_to_dok(bow_sents:List[List[int]], bow:BOW) -> dok_matrix:\n",
    "    nr_tokens = bow.nr_tokens + 1 # extra token for oov words.\n",
    "    dok = dok_matrix((len(bow_sents), nr_tokens), dtype='int')\n",
    "    for sent_number, sent in enumerate(bow_sents):\n",
    "        for token_id in sent:\n",
    "            dok[sent_number, token_id] += 1\n",
    "    return dok\n",
    "\n",
    "def split_train_dev_improved(train_dev_corpora:Dict[int, List[List[str]]], corpus_ids:Set[int], \n",
    "                    percentage_dev:Optional[float]=0.1) -> Tuple[List[List[str]], List[int], List[List[str]], List[int]]:\n",
    "    train_set = []\n",
    "    train_labels = []\n",
    "    dev_set = []\n",
    "    dev_labels = []\n",
    "    splitter = ShuffleSplit(1, test_size=percentage_dev, random_state=0)\n",
    "    for corpus_id in corpus_ids:\n",
    "        corpus_docs = train_dev_corpora[corpus_id]\n",
    "        train_indices, dev_indices = list(splitter.split(corpus_docs))[0]\n",
    "        \n",
    "        set_train_idx = set(train_indices)\n",
    "        for dev_index in dev_indices:\n",
    "            if dev_index in set_train_idx:\n",
    "                print('WRONG YO')\n",
    "            \n",
    "        \n",
    "        for train_index in train_indices:\n",
    "            train_set.append(corpus_docs[train_index])\n",
    "            train_labels.append(corpus_id)\n",
    "        \n",
    "        for dev_index in dev_indices:\n",
    "            dev_set.append(corpus_docs[dev_index])\n",
    "            dev_labels.append(corpus_id)\n",
    "    \n",
    "    return train_set, train_labels, dev_set, dev_labels\n",
    "\n",
    "def split_train_dev_baseline(train_dev_corpora:Dict[int, List[List[str]]], corpus_ids:Set[int], \n",
    "                    percentage_dev:Optional[float]=0.1) -> Tuple[List[List[str]], List[int], List[List[str]], List[int]]:\n",
    "    all_docs = []\n",
    "    all_labels = []\n",
    "    train_set = []\n",
    "    train_labels = []\n",
    "    dev_set = []\n",
    "    dev_labels = []\n",
    "    splitter = ShuffleSplit(1, test_size=percentage_dev, random_state=0)\n",
    "    for corpus_id in corpus_ids:\n",
    "        all_docs += train_dev_corpora[corpus_id]\n",
    "        all_labels += [corpus_id] * len(train_dev_corpora[corpus_id])\n",
    "        \n",
    "    train_indices, dev_indices = list(splitter.split(all_docs))[0]\n",
    "\n",
    "    for train_index in train_indices:\n",
    "        train_set.append(all_docs[train_index])\n",
    "        train_labels.append(all_labels[train_index])\n",
    "        \n",
    "    for dev_index in dev_indices:\n",
    "        dev_set.append(all_docs[dev_index])\n",
    "        dev_labels.append(all_labels[dev_index])\n",
    "    \n",
    "    return train_set, train_labels, dev_set, dev_labels\n",
    "\n",
    "def split_test(test_corpora:Dict[int, List[List[str]]], corpus_ids:Set[int]) -> Tuple[List[List[str]], List[int]]:\n",
    "    test_docs = []\n",
    "    test_labels = []\n",
    "    for corpus_id in corpus_ids:\n",
    "        for test_doc in test_corpora[corpus_id]:\n",
    "            test_docs.append(test_doc)\n",
    "            test_labels.append(corpus_id)\n",
    "    return test_docs, test_labels\n",
    "\n",
    "def compute_prf_scores(true_labels, pred_labels, value):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for idx in range(len(true_labels)):\n",
    "        true = true_labels[idx]\n",
    "        pred = pred_labels[idx]\n",
    "        if true == value and pred == value:\n",
    "            TP += 1\n",
    "        elif true == value and pred != value:\n",
    "            FN += 1\n",
    "        elif true != value and pred == value:\n",
    "            FP += 1\n",
    "    if TP + FP == 0 or TP + FN == 0:\n",
    "        return 0, 0, 0\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "def create_row(true:List[int], pred:List[int], system:str, split:str) -> str:\n",
    "    list_row = [system, split]\n",
    "    p_q, r_q, f_q = compute_prf_scores(true, pred, 0)\n",
    "    p_ot, r_ot, f_ot = compute_prf_scores(true, pred, 1)\n",
    "    p_nt, r_nt, f_nt = compute_prf_scores(true, pred, 2)\n",
    "    p_macro = (p_q + p_ot + p_nt)/3\n",
    "    r_macro = (r_q + r_ot + r_nt)/3\n",
    "    f_macro = (f_q + f_ot + f_nt)/3\n",
    "    values = [p_q, r_q, f_q, p_ot, r_ot, f_ot, p_nt, r_nt, f_nt, p_macro, r_macro, f_macro]\n",
    "    round_3 = partial(round, ndigits=3)\n",
    "    values = map(round_3, values)\n",
    "    values = map(str, values)\n",
    "    list_row += values\n",
    "    row = ','.join(list_row)\n",
    "    row += '\\n'\n",
    "    return row\n",
    "    \n",
    "def create_classification_output_file(output_file_name, \n",
    "                                      baseline_train_true, baseline_train_pred, \n",
    "                                      baseline_dev_true, baseline_dev_pred,\n",
    "                                      baseline_test_true, baseline_test_pred, \n",
    "                                      improved_train_true, improved_train_pred,\n",
    "                                      improved_dev_true, improved_dev_pred,\n",
    "                                      improved_test_true, improved_test_pred\n",
    "                                     ):\n",
    "    dictionary = dict()\n",
    "    keys_1 = ['baseline', 'improved']\n",
    "    keys_2 = ['train', 'dev', 'test']\n",
    "    dictionary['baseline'] = dict()\n",
    "    dictionary['improved'] = dict()\n",
    "    dictionary['baseline']['train'] = (baseline_train_true, baseline_train_pred)\n",
    "    dictionary['baseline']['dev'] = (baseline_dev_true, baseline_dev_pred)\n",
    "    dictionary['baseline']['test'] = (baseline_test_true, baseline_test_pred)\n",
    "    dictionary['improved']['train'] = (improved_train_true, improved_train_pred)\n",
    "    dictionary['improved']['dev'] = (improved_dev_true, improved_dev_pred)\n",
    "    dictionary['improved']['test'] = (improved_test_true, improved_test_pred)\n",
    "    # Current assumption: Quran:0, OT:1, NT:2.\n",
    "    with open(output_file_name, \"w\") as f:\n",
    "        f.write('system,split,p-quran,r-quran,f-quran,p-ot,r-ot,f-ot,p-nt,r-nt,f-nt,p-macro,r-macro,f-macro\\n')\n",
    "        for system in keys_1:\n",
    "            for split in keys_2:\n",
    "                true, pred = dictionary[system][split]\n",
    "                row = create_row(true, pred, system, split)\n",
    "                f.write(row)     \n",
    "\n",
    "def get_misclassified_docs(bow_sents:List[List[int]], bow:BOW, true:List[int], pred:List[int]):\n",
    "    for idx in range(len(true)):\n",
    "        if true[idx] != pred[idx]:\n",
    "            sent = bow_sents[idx]\n",
    "            print(str(true[idx]) + ' ' + str(pred[idx]) + ' ' + \n",
    "                  \" \".join(bow.reverse_transform_sent(sent)))\n",
    "            \n",
    "def plot_confusion_matrix(bow_sents:List[List[int]], bow:BOW, true:List[int], pred:List[int]):\n",
    "    cm = np.zeros((3,3))\n",
    "    for idx in range(len(true)):\n",
    "        ii = true[idx]\n",
    "        jj = pred[idx]\n",
    "        cm[ii, jj] += 1\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for task 1.\n",
    "# qrels = pd.read_csv('./qrels.csv')\n",
    "# sys_results = pd.read_csv('./system_results.csv')\n",
    "# nr_queries = get_number_of_unique_rows(sys_results, 'query_number')\n",
    "# nr_systems = get_number_of_unique_rows(sys_results, 'system_number')\n",
    "# result_df = create_result_df(nr_systems, nr_queries)\n",
    "# calculate_all_precision_at_10(sys_results, qrels, nr_systems, nr_queries, result_df)\n",
    "# calculate_all_recall_at_50(sys_results, qrels, nr_systems, nr_queries, result_df)\n",
    "# calculate_all_R_precision(sys_results, qrels, nr_systems, nr_queries, result_df)\n",
    "# calculate_all_AP(sys_results, qrels, nr_systems, nr_queries, result_df)\n",
    "# calculate_all_nDCG(sys_results, qrels, nr_systems, nr_queries, result_df)\n",
    "# score_means = print_result_df(result_df, nr_systems, nr_queries)\n",
    "# col_names = ['P@10', 'R@50', 'r-precision', 'AP', 'nDCG@10', 'nDCG@20']\n",
    "# p_values(result_df, score_means, nr_queries, col_names)\n",
    "\n",
    "# Part 2 code ----------------------------------------------------------------------------\n",
    "tsv_file_name = 'train_and_dev.tsv'\n",
    "stopwords_file_name = \"englishST.txt\"\n",
    "index_output_file_name = \"index.txt\"\n",
    "\n",
    "stopwords_set = construct_stopwords_set(stopwords_file_name)\n",
    "tokenizer = SimpleTokenizer('[a-zA-Z]+')\n",
    "stemmer = PorterStemmer()\n",
    "preprocessor = SimplePreprocessor(tokenizer, stopwords_set, stemmer)\n",
    "\n",
    "corpus_names_to_int = {'Quran':0, 'OT':1, 'NT':2}\n",
    "int_to_corpus_names = {0:'Quran', 1:'OT', 2:'NT'}\n",
    "\n",
    "corpora = read_tsv_extract_corpora(tsv_file_name, corpus_names_to_int)\n",
    "corpora = preprocess_corpora(corpora, preprocessor)\n",
    "\n",
    "\n",
    "index, corpora_nr_docs = read_corpora_and_create_index(corpora)\n",
    "\n",
    "MI_scores, chi_scores = compute_MI_chi_scores(index, corpora_nr_docs, corpus_names_to_int.values())\n",
    "print_top_k_terms_for_each_corpus(MI_scores, chi_scores, int_to_corpus_names, 10)\n",
    "\n",
    "run_topics_task(corpora, corpora_nr_docs)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part 3 code.\n",
    "tokenizer = SimpleTokenizer('[a-zA-Z]+')\n",
    "\n",
    "tsv_file_name = 'train_and_dev.tsv'\n",
    "test_tsv_file_name = 'test.tsv'\n",
    "stopwords_file_name = \"englishST.txt\"\n",
    "output_file_name = \"classification.csv\"\n",
    "kjv_file_name = 't_kjv.csv'\n",
    "\n",
    "corpus_names_to_int = {'Quran':0, 'OT':1, 'NT':2}\n",
    "int_to_corpus_names = {0:'Quran', 1:'OT', 2:'NT'}\n",
    "corpus_ids = set([0, 1, 2])\n",
    "\n",
    "corpora = read_tsv_extract_corpora(tsv_file_name, corpus_names_to_int)\n",
    "test_corpora = read_tsv_extract_corpora(test_tsv_file_name, corpus_names_to_int)\n",
    "\n",
    "tokenized_corpora = tokenize_corpora(corpora, tokenizer)\n",
    "test_tokenized_corpora = tokenize_corpora(test_corpora, tokenizer)\n",
    "\n",
    "baseline_train_docs, baseline_train_labels, baseline_dev_docs, baseline_dev_labels = split_train_dev_baseline(tokenized_corpora, corpus_ids)\n",
    "baseline_test_docs, baseline_test_labels = split_test(test_tokenized_corpora, corpus_ids)\n",
    "\n",
    "baseline_train_bow_sents, bow = docs_to_bow_sents(baseline_train_docs)\n",
    "baseline_dev_bow_sents = docs_to_bow_sents(baseline_dev_docs, bow)[0]\n",
    "baseline_test_bow_sents = docs_to_bow_sents(baseline_test_docs, bow)[0]\n",
    "\n",
    "baseline_train_dok = bow_sents_to_dok(baseline_train_bow_sents, bow)\n",
    "baseline_dev_dok = bow_sents_to_dok(baseline_dev_bow_sents, bow)\n",
    "baseline_test_dok = bow_sents_to_dok(baseline_test_bow_sents, bow)\n",
    "\n",
    "baseline_model = SVC(C=1000)\n",
    "baseline_model.fit(baseline_train_dok, baseline_train_labels)\n",
    "baseline_train_pred = baseline_model.predict(baseline_train_dok)\n",
    "baseline_dev_pred = baseline_model.predict(baseline_dev_dok)\n",
    "baseline_test_pred = baseline_model.predict(baseline_test_dok)\n",
    "\n",
    "\n",
    "# Part 3 code for preprocessing tests.-----------------------------------------------------------\n",
    "# tokenizer = SimpleTokenizer('[a-zA-Z]+')\n",
    "\n",
    "# preprocessed_corpora = tokenize_corpora(corpora, tokenizer)\n",
    "# test_preprocessed_corpora = tokenize_corpora(test_corpora, tokenizer)\n",
    "\n",
    "# improved_train_docs, improved_train_labels, improved_dev_docs, improved_dev_labels = split_train_dev_improved(preprocessed_corpora, corpus_ids)\n",
    "# improved_test_docs, improved_test_labels = split_test(test_preprocessed_corpora, corpus_ids)\n",
    "\n",
    "# improved_train_bow_sents, improved_bow = docs_to_bow_sents(improved_train_docs)\n",
    "# improved_dev_bow_sents = docs_to_bow_sents(improved_dev_docs, improved_bow)[0]\n",
    "# improved_test_bow_sents = docs_to_bow_sents(improved_test_docs, improved_bow)[0]\n",
    "\n",
    "# improved_train_dok = bow_sents_to_dok(improved_train_bow_sents, improved_bow)\n",
    "# improved_dev_dok = bow_sents_to_dok(improved_dev_bow_sents, improved_bow)\n",
    "# improved_test_dok = bow_sents_to_dok(improved_test_bow_sents, improved_bow)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# Task 3 extra data experiment-----------------------------------------------------------\n",
    "# def replace_NT_OT_docs(corpora:Dict[int, List[str]], kjv_file_name:str) -> Dict[int, List[str]]:\n",
    "#     new_corpora = dict()\n",
    "#     new_corpora[0] = corpora[0]\n",
    "#     new_corpora[1] = []\n",
    "#     new_corpora[2] = []\n",
    "#     with open(kjv_file_name, mode='r', newline='\\n') as f:\n",
    "#         read_tsv = csv.reader(f, delimiter=\",\")\n",
    "#         for row in read_tsv:\n",
    "#             if row[1] == 'b':\n",
    "#                 continue\n",
    "#             chapter = int(row[1])\n",
    "#             if chapter < 40:\n",
    "#                 new_corpora[1].append(row[4])\n",
    "#             elif chapter >= 40:\n",
    "#                 new_corpora[2].append(row[4])\n",
    "#     return new_corpora\n",
    "\n",
    "# new_corpora = replace_NT_OT_docs(corpora, kjv_file_name)\n",
    "# test_corpora = read_tsv_extract_corpora(test_tsv_file_name, corpus_names_to_int)\n",
    "\n",
    "# preprocessed_corpora = tokenize_corpora(new_corpora, tokenizer)\n",
    "# test_preprocessed_corpora = tokenize_corpora(test_corpora, tokenizer)\n",
    "\n",
    "# improved_train_docs, improved_train_labels, improved_dev_docs, improved_dev_labels = split_train_dev_improved(preprocessed_corpora, corpus_ids)\n",
    "# improved_test_docs, improved_test_labels = split_test(test_preprocessed_corpora, corpus_ids)\n",
    "\n",
    "# improved_train_bow_sents, improved_bow = docs_to_bow_sents(improved_train_docs)\n",
    "# improved_dev_bow_sents = docs_to_bow_sents(improved_dev_docs, improved_bow)[0]\n",
    "# improved_test_bow_sents = docs_to_bow_sents(improved_test_docs, improved_bow)[0]\n",
    "\n",
    "# improved_train_dok = bow_sents_to_dok(improved_train_bow_sents, improved_bow)\n",
    "# improved_dev_dok = bow_sents_to_dok(improved_dev_bow_sents, improved_bow)\n",
    "# improved_test_dok = bow_sents_to_dok(improved_test_bow_sents, improved_bow)\n",
    "\n",
    "# improved_model = SVC(C=1000)\n",
    "# improved_model.fit(improved_train_dok, improved_train_labels)\n",
    "# improved_train_pred = improved_model.predict(improved_train_dok)\n",
    "# improved_dev_pred = improved_model.predict(improved_dev_dok)\n",
    "# improved_test_pred = improved_model.predict(improved_test_dok)\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "create_classification_output_file(output_file_name,\n",
    "                                 baseline_train_labels, baseline_train_pred,\n",
    "                                 baseline_dev_labels, baseline_dev_pred,\n",
    "                                 baseline_test_labels, baseline_test_pred,\n",
    "                                 improved_train_labels, improved_train_pred,\n",
    "                                 improved_dev_labels, improved_dev_pred,\n",
    "                                 improved_test_labels, improved_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
